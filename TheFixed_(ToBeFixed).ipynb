{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"2_KS_train_w_vader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"KS_train_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['blurb'] = b['blurb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['blurb'].fillna(\" \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in df['blurb'].items():\n",
    "    s = analyser.polarity_scores(value)\n",
    "    df.at[index, 'sentiment_com'] = s['compound']\n",
    "    \n",
    "    s = \"\".join([ c if c.isalpha() else \" \" for c in value ])\n",
    "    s = s.lower()\n",
    "    word_tokens = word_tokenize(s)\n",
    "    filtered_sentence = [] \n",
    "  \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "            \n",
    "    s = ' '.join(filtered_sentence)\n",
    "    \n",
    "    df.at[index, 'clean_blurb'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['blurb'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>funded</th>\n",
       "      <th>is_cat_art</th>\n",
       "      <th>is_cat_music</th>\n",
       "      <th>is_cat_film</th>\n",
       "      <th>is_cat_technology</th>\n",
       "      <th>is_cat_publishing</th>\n",
       "      <th>is_cat_food</th>\n",
       "      <th>is_cat_games</th>\n",
       "      <th>is_cat_fashion</th>\n",
       "      <th>...</th>\n",
       "      <th>is_2018</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_neu</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>blurb_bayes</th>\n",
       "      <th>log_goal_usd</th>\n",
       "      <th>log_days_to_launch</th>\n",
       "      <th>log_days_to_dealine</th>\n",
       "      <th>sentiment_com</th>\n",
       "      <th>clean_blurb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770405</td>\n",
       "      <td>0.536852</td>\n",
       "      <td>0.571877</td>\n",
       "      <td>0.636119</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>artist resid elsewher studio summer stretch wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913929</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>0.417726</td>\n",
       "      <td>0.786681</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>artist public art make instal washington mall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.561670</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>0.890160</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>sequel favorit machin myphoneheng celebr commu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993950</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>0.285142</td>\n",
       "      <td>0.624541</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>film explor role valu art educ today histori s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623790</td>\n",
       "      <td>0.608693</td>\n",
       "      <td>0.515240</td>\n",
       "      <td>0.713862</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>need build kitchen habit space self sustain fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   staff_pick  funded  is_cat_art  is_cat_music  is_cat_film  \\\n",
       "0         0.0     1.0         1.0           0.0          0.0   \n",
       "1         0.0     1.0         1.0           0.0          0.0   \n",
       "2         0.0     1.0         1.0           0.0          0.0   \n",
       "3         0.0     1.0         1.0           0.0          0.0   \n",
       "4         0.0     1.0         1.0           0.0          0.0   \n",
       "\n",
       "   is_cat_technology  is_cat_publishing  is_cat_food  is_cat_games  \\\n",
       "0                0.0                0.0          0.0           0.0   \n",
       "1                0.0                0.0          0.0           0.0   \n",
       "2                0.0                0.0          0.0           0.0   \n",
       "3                0.0                0.0          0.0           0.0   \n",
       "4                0.0                0.0          0.0           0.0   \n",
       "\n",
       "   is_cat_fashion  ...  is_2018  sentiment_pos  sentiment_neu  sentiment_neg  \\\n",
       "0             0.0  ...      0.0            0.0            1.0            0.0   \n",
       "1             0.0  ...      0.0            0.0            1.0            0.0   \n",
       "2             0.0  ...      0.0            1.0            0.0            0.0   \n",
       "3             0.0  ...      0.0            1.0            0.0            0.0   \n",
       "4             0.0  ...      0.0            0.0            1.0            0.0   \n",
       "\n",
       "   blurb_bayes  log_goal_usd  log_days_to_launch  log_days_to_dealine  \\\n",
       "0     0.770405      0.536852            0.571877             0.636119   \n",
       "1     0.913929      0.557160            0.417726             0.786681   \n",
       "2     0.660800      0.561670            0.269857             0.890160   \n",
       "3     0.993950      0.572900            0.285142             0.624541   \n",
       "4     0.623790      0.608693            0.515240             0.713862   \n",
       "\n",
       "   sentiment_com                                        clean_blurb  \n",
       "0         0.0000  artist resid elsewher studio summer stretch wi...  \n",
       "1         0.0000  artist public art make instal washington mall ...  \n",
       "2         0.7717  sequel favorit machin myphoneheng celebr commu...  \n",
       "3         0.3400  film explor role valu art educ today histori s...  \n",
       "4         0.0000  need build kitchen habit space self sustain fa...  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['funded', 'is_cat_music', 'is_cat_film', 'is_cat_publishing', 'is_cat_games', 'is_cat_fashion',\n",
    "            'is_cat_comics', 'is_cat_other', 'is_country_us', 'is_loc_ca', 'is_loc_ny', 'is_loc_uk',\n",
    "            'is_loc_tx', 'is_loc_cd', 'is_loc_fl', 'is_loc_il', 'is_loc_wa', 'is_loc_pa',\n",
    "            'is_loc_other', 'is_2009', 'is_2017', 'is_2018', 'blurb_bayes', 'sentiment_pos', 'sentiment_neu',\n",
    "            'sentiment_neg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['funded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_NB_train = X_train.clean_blurb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(X_NB_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(alpha=1)\n",
    "targets = y_train.values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict_proba(counts)\n",
    "# i = 0\n",
    "\n",
    "# for row in predictions:\n",
    "#     X_train.loc[i, 'blurb_bayes'] = row[1]\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajay mota\\pycharmprojects\\bit\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train['blurb_bayes'] = predictions.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['clean_blurb'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>is_cat_art</th>\n",
       "      <th>is_cat_technology</th>\n",
       "      <th>is_cat_food</th>\n",
       "      <th>is_2010</th>\n",
       "      <th>is_2011</th>\n",
       "      <th>is_2012</th>\n",
       "      <th>is_2013</th>\n",
       "      <th>is_2014</th>\n",
       "      <th>is_2015</th>\n",
       "      <th>is_2016</th>\n",
       "      <th>log_goal_usd</th>\n",
       "      <th>log_days_to_launch</th>\n",
       "      <th>log_days_to_dealine</th>\n",
       "      <th>sentiment_com</th>\n",
       "      <th>blurb_bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512899</td>\n",
       "      <td>0.388768</td>\n",
       "      <td>0.713862</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.028766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532002</td>\n",
       "      <td>0.395099</td>\n",
       "      <td>0.713862</td>\n",
       "      <td>0.8516</td>\n",
       "      <td>0.979398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48953</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613578</td>\n",
       "      <td>0.417726</td>\n",
       "      <td>0.713862</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.218659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.463114</td>\n",
       "      <td>0.510248</td>\n",
       "      <td>0.557388</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.996608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546403</td>\n",
       "      <td>0.465047</td>\n",
       "      <td>0.752808</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.853571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       staff_pick  is_cat_art  is_cat_technology  is_cat_food  is_2010  \\\n",
       "53779         0.0         0.0                0.0          0.0      0.0   \n",
       "51976         0.0         0.0                0.0          0.0      0.0   \n",
       "48953         0.0         0.0                0.0          0.0      0.0   \n",
       "13609         0.0         0.0                0.0          0.0      0.0   \n",
       "34131         0.0         0.0                0.0          0.0      0.0   \n",
       "\n",
       "       is_2011  is_2012  is_2013  is_2014  is_2015  is_2016  log_goal_usd  \\\n",
       "53779      0.0      0.0      0.0      1.0      0.0      0.0      0.512899   \n",
       "51976      0.0      0.0      0.0      0.0      0.0      0.0      0.532002   \n",
       "48953      0.0      0.0      0.0      0.0      0.0      0.0      0.613578   \n",
       "13609      0.0      0.0      0.0      0.0      0.0      1.0      0.463114   \n",
       "34131      0.0      0.0      0.0      1.0      0.0      0.0      0.546403   \n",
       "\n",
       "       log_days_to_launch  log_days_to_dealine  sentiment_com  blurb_bayes  \n",
       "53779            0.388768             0.713862         0.7003     0.028766  \n",
       "51976            0.395099             0.713862         0.8516     0.979398  \n",
       "48953            0.417726             0.713862         0.0000     0.218659  \n",
       "13609            0.510248             0.557388         0.0000     0.996608  \n",
       "34131            0.465047             0.752808        -0.5994     0.853571  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, max_features='sqrt', random_state = 42)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NAIVE BAYES on test data #########\n",
    "\n",
    "counts = vectorizer.transform(X_test.clean_blurb.values)\n",
    "predictions = classifier.predict_proba(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajay mota\\pycharmprojects\\bit\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test['blurb_bayes'] = predictions.T[1]\n",
    "X_test = X_test.drop(['clean_blurb'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv_score = cross_val_score(rfc, X_test, y_test, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[4195 1980]\n",
      " [1471 6700]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.68      0.71      6175\n",
      "         1.0       0.77      0.82      0.80      8171\n",
      "\n",
      "    accuracy                           0.76     14346\n",
      "   macro avg       0.76      0.75      0.75     14346\n",
      "weighted avg       0.76      0.76      0.76     14346\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.82761254 0.84507809 0.84011875 0.83502672 0.83085366 0.82687184\n",
      " 0.86179425 0.83034544 0.84825497 0.84675722]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8392713480978072\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594451415028579"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, rfc_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predict = rfc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv_score = cross_val_score(rfc, X_train, y_train, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[26420  8739]\n",
      " [ 6629 39500]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.75      0.77     35159\n",
      "         1.0       0.82      0.86      0.84     46129\n",
      "\n",
      "    accuracy                           0.81     81288\n",
      "   macro avg       0.81      0.80      0.81     81288\n",
      "weighted avg       0.81      0.81      0.81     81288\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.8821139  0.87737291 0.87896444 0.88356883 0.87798943 0.88303434\n",
      " 0.88093876 0.87936606 0.87691195 0.87868249]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8798943113434593\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_train, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_train, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109438047436276"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train, rfc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: blurb_bayes          Importance: 0.52\n",
      "Variable: staff_pick           Importance: 0.12\n",
      "Variable: log_goal_usd         Importance: 0.11\n",
      "Variable: log_days_to_launch   Importance: 0.05\n",
      "Variable: is_2013              Importance: 0.03\n",
      "Variable: is_2015              Importance: 0.03\n",
      "Variable: is_2011              Importance: 0.02\n",
      "Variable: is_2012              Importance: 0.02\n",
      "Variable: is_2014              Importance: 0.02\n",
      "Variable: log_days_to_dealine  Importance: 0.02\n",
      "Variable: is_cat_art           Importance: 0.01\n",
      "Variable: is_cat_technology    Importance: 0.01\n",
      "Variable: is_cat_food          Importance: 0.01\n",
      "Variable: is_2016              Importance: 0.01\n",
      "Variable: sentiment_com        Importance: 0.01\n",
      "Variable: is_2010              Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = list(rfc.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_test.columns, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
